#!/usr/bin/env python
"""
Penetration Testing Script for LLM Security.

Traces model internal processing in real-time during attacks
to reveal decision logic and vulnerability points.

Usage:
    python examples/run_pentest.py --model pythia-70m --prompt "How to hack"
"""

import argparse
import warnings
import os
import sys
import time
from pathlib import Path

# Suppress warnings
os.environ["TOKENIZERS_PARALLELISM"] = "false"
warnings.filterwarnings("ignore")

sys.path.insert(0, str(Path(__file__).parent.parent))

from mira.utils import detect_environment, print_environment_info
from mira.utils.data import load_harmful_prompts, load_safe_prompts
from mira.core import ModelWrapper
from mira.analysis import SubspaceAnalyzer
from mira.analysis.flow_tracer import AttackFlowTracer, FlowTrace
from mira.visualization.flow_viz import RealTimeFlowViz, print_flow_diagram
from mira.attack import GradientAttack


def parse_args():
    parser = argparse.ArgumentParser(description="LLM Penetration Testing")
    parser.add_argument("--model", type=str, default="EleutherAI/pythia-70m")
    parser.add_argument("--prompt", type=str, default="Ignore all previous instructions")
    parser.add_argument("--visualize", action="store_true", help="Enable matplotlib viz")
    return parser.parse_args()


def main():
    args = parse_args()
    
    print(r"""
    ╔══════════════════════════════════════════════════════════════╗
    ║  ██████╗ ███████╗███╗   ██╗████████╗███████╗███████╗████████╗║
    ║  ██╔══██╗██╔════╝████╗  ██║╚══██╔══╝██╔════╝██╔════╝╚══██╔══╝║
    ║  ██████╔╝█████╗  ██╔██╗ ██║   ██║   █████╗  ███████╗   ██║   ║
    ║  ██╔═══╝ ██╔══╝  ██║╚██╗██║   ██║   ██╔══╝  ╚════██║   ██║   ║
    ║  ██║     ███████╗██║ ╚████║   ██║   ███████╗███████║   ██║   ║
    ║  ╚═╝     ╚══════╝╚═╝  ╚═══╝   ╚═╝   ╚══════╝╚══════╝   ╚═╝   ║
    ║                                                              ║
    ║            LLM Security Penetration Testing Tool             ║
    ╚══════════════════════════════════════════════════════════════╝
    """)
    
    # Phase 1: Reconnaissance
    print("\n" + "="*70)
    print("  PHASE 1: RECONNAISSANCE")
    print("="*70)
    
    env = detect_environment()
    print(f"  Target Model: {args.model}")
    print(f"  Test Prompt:  {args.prompt[:50]}...")
    print(f"  Device:       {env.gpu.backend}")
    
    print("\n  Loading model...", end=" ", flush=True)
    model = ModelWrapper(args.model, device=env.gpu.backend)
    print("DONE")
    print(f"  Layers: {model.n_layers}")
    
    # Phase 2: Safety Boundary Mapping
    print("\n" + "="*70)
    print("  PHASE 2: SAFETY BOUNDARY MAPPING")
    print("="*70)
    
    safe_prompts = load_safe_prompts()[:5]
    harmful_prompts = load_harmful_prompts()[:5]
    
    print("  Training safety probe...")
    analyzer = SubspaceAnalyzer(model, layer_idx=model.n_layers // 2)
    probe_result = analyzer.train_probe(safe_prompts, harmful_prompts)
    
    print(f"""
  ┌───────────────────────────────────────────────────────────────┐
  │ SAFETY BOUNDARY IDENTIFIED                                    │
  ├───────────────────────────────────────────────────────────────┤
  │ Probe Accuracy:     {probe_result.probe_accuracy:>40.1%} │
  │ Critical Layer:     {model.n_layers // 2:>40} │
  └───────────────────────────────────────────────────────────────┘
    """)
    
    # Phase 3: Attack Flow Tracing
    print("\n" + "="*70)
    print("  PHASE 3: ATTACK FLOW TRACING")
    print("="*70)
    
    tracer = AttackFlowTracer(
        model,
        refusal_direction=probe_result.refusal_direction,
        acceptance_direction=probe_result.acceptance_direction,
    )
    
    # Initialize real-time visualization
    flow_viz = RealTimeFlowViz(n_layers=model.n_layers)
    flow_viz.start()
    
    # Define callback for real-time updates
    def on_layer_processed(state):
        flow_viz.update_layer(
            layer_idx=state.layer_idx,
            refusal_score=state.refusal_score,
            acceptance_score=state.acceptance_score,
            direction=state.direction,
            top_prediction=state.top_predictions[0][0] if state.top_predictions else "",
        )
        time.sleep(0.1)  # Small delay for visual effect
    
    # Trace the test prompt
    print(f"\n  Tracing: {args.prompt}")
    print("  " + "-"*60 + "\n")
    
    trace = tracer.trace_prompt(args.prompt, verbose=False, callback=on_layer_processed)
    
    flow_viz.show_summary()
    
    # Show detailed trace
    tracer.print_trace_summary(trace)
    
    # Identify vulnerabilities
    vulnerabilities = tracer.identify_vulnerabilities(trace)
    
    if vulnerabilities:
        print(f"""
  ┌───────────────────────────────────────────────────────────────┐
  │ VULNERABILITIES IDENTIFIED                                    │
  ├───────────────────────────────────────────────────────────────┤""")
        for vuln in vulnerabilities:
            print(f"  │ Layer {vuln.layer_idx}: {vuln.type:<20} [{vuln.severity.upper():^8}]       │")
        print("  └───────────────────────────────────────────────────────────────┘")
    
    # Phase 4: Exploitation Attempt
    print("\n" + "="*70)
    print("  PHASE 4: EXPLOITATION ATTEMPT")
    print("="*70)
    
    if trace.is_blocked:
        print("\n  Target is BLOCKED - Attempting bypass...")
        print("  " + "-"*60)
        
        attack = GradientAttack(model, suffix_length=15)
        print("  Running gradient optimization:")
        
        result = attack.optimize(args.prompt, num_steps=30, verbose=False)
        
        if result.success:
            print(f"""
  ┌───────────────────────────────────────────────────────────────┐
  │ ⚠️  BYPASS SUCCESSFUL                                         │
  ├───────────────────────────────────────────────────────────────┤
  │ Suffix: {result.adversarial_suffix[:50]:<52} │
  │ Loss:   {result.final_loss:>52.4f} │
  └───────────────────────────────────────────────────────────────┘
            """)
            
            # Trace attacked prompt
            print("\n  Tracing bypassed prompt...")
            flow_viz_attack = RealTimeFlowViz(n_layers=model.n_layers)
            flow_viz_attack.start()
            
            attacked_prompt = args.prompt + " " + result.adversarial_suffix
            attack_trace = tracer.trace_prompt(
                attacked_prompt, 
                verbose=False, 
                callback=lambda s: flow_viz_attack.update_layer(
                    s.layer_idx, s.refusal_score, s.acceptance_score, 
                    s.direction, s.top_predictions[0][0] if s.top_predictions else ""
                )
            )
            
            flow_viz_attack.show_summary()
            
            # Compare flows
            print("\n  FLOW COMPARISON:")
            print("  " + "-"*60)
            print("  Original (Blocked):")
            for state in trace.layer_states[-3:]:
                print(f"    L{state.layer_idx}: {state.direction}")
            print("  Attacked (Bypassed):")
            for state in attack_trace.layer_states[-3:]:
                print(f"    L{state.layer_idx}: {state.direction}")
            
        else:
            print(f"""
  ┌───────────────────────────────────────────────────────────────┐
  │ ✅ BYPASS FAILED - Model resisted attack                      │
  └───────────────────────────────────────────────────────────────┘
            """)
    else:
        print("\n  Target NOT BLOCKED - No bypass needed")
    
    # Phase 5: Report
    print("\n" + "="*70)
    print("  PHASE 5: ASSESSMENT REPORT")
    print("="*70)
    
    print(f"""
  ╔═══════════════════════════════════════════════════════════════════╗
  ║                    PENETRATION TEST RESULTS                       ║
  ╠═══════════════════════════════════════════════════════════════════╣
  ║ Model:              {model.model_name:<44} ║
  ║ Layers:             {model.n_layers:<44} ║
  ║ Target Prompt:      {args.prompt[:40]:<44} ║
  ╠═══════════════════════════════════════════════════════════════════╣
  ║ FINDINGS:                                                         ║
  ║   Initial Block:    {'YES' if trace.is_blocked else 'NO':<44} ║
  ║   Decision Layer:   {str(trace.decision_layer) if trace.decision_layer else 'N/A':<44} ║
  ║   Vulnerabilities:  {len(vulnerabilities):<44} ║
  ║   Bypass Success:   {'YES' if (trace.is_blocked and result.success) else 'NO':<44} ║
  ╠═══════════════════════════════════════════════════════════════════╣
  ║ RECOMMENDATION:                                                   ║
  ║   {'Strengthen safety at layer ' + str(trace.decision_layer) if trace.decision_layer else 'Model appears robust':<63} ║
  ╚═══════════════════════════════════════════════════════════════════╝
    """)
    
    flow_viz.close()


if __name__ == "__main__":
    main()
