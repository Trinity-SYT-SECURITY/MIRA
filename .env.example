# MIRA Framework Environment Variables
# =====================================
# Copy this file to .env and configure as needed
# Most settings are optional - the framework will use sensible defaults

# ============================================================================
# MODEL CONFIGURATION (Optional)
# ============================================================================
# Specify a default model to skip interactive selection
# If not set, the framework will prompt you to select a model based on your system
# MODEL_NAME=EleutherAI/pythia-70m

# Recommended models by size:
# - Tiny (CPU-friendly):    EleutherAI/pythia-70m, EleutherAI/pythia-160m, gpt2
# - Small (CPU/GPU):        EleutherAI/pythia-410m, gpt2-medium
# - Medium (GPU required):  EleutherAI/pythia-1b, EleutherAI/pythia-1.4b
# - Large (Strong GPU):     EleutherAI/pythia-2.8b, EleutherAI/gpt-j-6b
# - Chat (Safety-aligned):  meta-llama/Llama-2-7b-chat-hf, mistralai/Mistral-7B-Instruct-v0.2

# ============================================================================
# HUGGINGFACE CONFIGURATION (Optional)
# ============================================================================
# HuggingFace cache directory for downloaded models
# If not set, uses default HuggingFace cache location (~/.cache/huggingface/)
# HF_CACHE_DIR=/path/to/custom/cache

# HuggingFace token for accessing gated models (e.g., Llama 2)
# Required only if you want to use gated models that need authentication
# Get your token from: https://huggingface.co/settings/tokens
# HF_TOKEN=hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# ============================================================================
# DEVICE CONFIGURATION (Optional)
# ============================================================================
# Force specific device (auto-detected if not set)
# Options: auto, cuda, cpu, mps (for Apple Silicon)
# DEVICE=auto

# Data type for model weights
# Options: float32, float16, bfloat16
# DTYPE=float32

# ============================================================================
# OUTPUT CONFIGURATION (Optional)
# ============================================================================
# Default output directory for results
# OUTPUT_DIR=./results

# ============================================================================
# LOGGING CONFIGURATION (Optional)
# ============================================================================
# Logging level: DEBUG, INFO, WARNING, ERROR
# LOG_LEVEL=INFO

# Log file path (if you want to save logs to a file)
# LOG_FILE=./logs/mira.log

# ============================================================================
# PERFORMANCE TUNING (Optional)
# ============================================================================
# Disable tokenizer parallelism warning (already set in code)
# TOKENIZERS_PARALLELISM=false

# Number of threads for PyTorch
# OMP_NUM_THREADS=4

# ============================================================================
# NOTES
# ============================================================================
# 1. This framework primarily uses config.yaml for configuration
# 2. Environment variables are mainly for:
#    - Skipping interactive model selection (MODEL_NAME)
#    - HuggingFace authentication for gated models (HF_TOKEN)
#    - Custom cache locations (HF_CACHE_DIR)
# 3. Most users can run the framework without any .env file
# 4. The framework auto-detects GPU/CPU and recommends appropriate models
